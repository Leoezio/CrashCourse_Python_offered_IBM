{
    "nbformat": 4, 
    "cells": [
        {
            "source": "# Python Text Crash Course_Part 2 Data Preparation\n## Missing, Distinct Value, Scaling\n\n## Full Day Workshop for user learn Data Science with Python\n### 2017 Dec Timothy CL Lam\nThis is meant for internal usage, part of contents copied externally, not for commercial purpose\n", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "# The Case for Convolutional Neural Networks\nGiven a dataset of gray scale images with the standardized size of 32 \u0002 32 pixels each, a\ntraditional feedforward neural network would require 1,024 input weights (plus one bias). This\nis fair enough, but the \nattening of the image matrix of pixels to a long vector of pixel values\nloses all of the spatial structure in the image. Unless all of the images are perfectly resized, the\nneural network will have great di\u000eculty with the problem.\nConvolutional Neural Networks expect and preserve the spatial relationship between pixels\nby learning internal feature representations using small squares of input data. Features are\nlearned and used across the whole image, allowing for the objects in the images to be shifted or\ntranslated in the scene and still detectable by the network. It is this reason why the network is\nso useful for object recognition in photographs, picking out digits, faces, objects and so on with\nvarying orientation. In summary, below are some of the bene\fts of using convolutional neural\nnetworks:\n\n\n- They use fewer parameters (weights) to learn than a fully connected network.\n\n- They are designed to be invariant to object position and distortion in the scene.\n\u0088\n- They automatically learn and generalize features from the input domain.", 
            "cell_type": "markdown", 
            "metadata": {
                "collapsed": true
            }
        }, 
        {
            "source": "## Building Blocks of Convolutional Neural Networks\nThere are three types of layers in a Convolutional Neural Network:\n1. Convolutional Layers.\n2. Pooling Layers.\n3. Fully-Connected Layers. ", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "## Convolutional Layers\nConvolutional layers are comprised of \flters and feature maps.\n\n###  Filters\nThe \flters are essentially the neurons of the layer. They have both weighted inputs and generate\nan output value like a neuron. The input size is a \fxed square called a patch or a receptive\n\feld. If the convolutional layer is an input layer, then the input patch will be pixel values. If\nthey deeper in the network architecture, then the convolutional layer will take input from a\nfeature map from the previous layer.\n\n###  Feature Maps\nThe feature map is the output of one \flter applied to the previous layer. A given \flter is drawn\nacross the entire previous layer and moved one pixel at a time. Each position results in an\nactivation of the neuron and the output is collected in the feature map. You can see that if the\nreceptive \feld is moved one pixel from activation to activation, then the \feld will overlap with\nthe previous activation by (\feld width - 1) input values.\nThe distance that \flter is moved across the input from the previous layer each activation is\nreferred to as the stride. If the size of the previous layer is not cleanly divisible by the size of\nthe \flter's receptive \feld and the size of the stride then it is possible for the receptive \feld to\nattempt to read o\u000b the edge of the input feature map. In this case, techniques like zero padding\ncan be used to invent mock inputs with zero values for the receptive \feld to read.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "## Pooling Layers\nThe pooling layers down-sample the previous layers feature map. Pooling layers follow a sequence\nof one or more convolutional layers and are intended to consolidate the features learned and\nexpressed in the previous layer's feature map. As such, pooling may be considered a technique\nto compress or generalize feature representations and generally reduce the over\ftting of the\ntraining data by the model.\nThey too have a receptive \feld, often much smaller than the convolutional layer. Also, the\nstride or number of inputs that the receptive \feld is moved for each activation is often equal to\nthe size of the receptive \feld to avoid any overlap. Pooling layers are often very simple, taking\nthe average or the maximum of the input value in order to create its own feature map.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "## Fully Connected Layers\nFully connected layers are the normal \nat feedforward neural network layer. These layers may\nhave a nonlinear activation function or a softmax activation in order to output probabilities\nof class predictions. Fully connected layers are used at the end of the network after feature\nextraction and consolidation has been performed by the convolutional and pooling layers. They\nare used to create \fnal nonlinear combinations of features and for making predictions by the\nnetwork. ", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "# Convolutional Neural Networks Best Practices\n\nNow that we know about the building blocks for a convolutional neural network and how the\nlayers hang together, we can review some best practices to consider when applying them.\n\u0088\n- Input Receptive Field Dimensions: The default is 2D for images, but could be 1D such as for words in a sentence or 3D for video that adds a time dimension. Receptive Field Size: The patch should be as small as possible, but large enough to see features in the input data. It is common to use 3 \u0002 3 on small images and 5 \u0002 5 or 7 \u0002 7 and more on larger image sizes.\n\u0088 \n- Stride Width: Use the default stride of 1. It is easy to understand and you don't need padding to handle the receptive \feld falling o\u000b the edge of your images. This could be increased to 2 or larger for larger images. Number of Filters: Filters are the feature detectors. Generally fewer \flters are used at the input layer and increasingly more \flters used at deeper layers.\n\u0088 \n- Padding: Set to zero and called zero padding when reading non-input data. This is useful when you cannot or do not want to standardize input image sizes or when you want to use receptive \feld and stride sizes that do not neatly divide up the input image size.\n\u0088 \n- Pooling: Pooling is a destructive or generalization process to reduce over\ftting. Receptive \feld size is almost always set to 2 \u0002 2 with a stride of 2 to discard 75% of the activations from the output of the previous layer.\n\n- Data Preparation: Consider standardizing input data, both the dimensions of the images and pixel values.\n\n- Pattern Architecture: It is common to pattern the layers in your network architecture. This might be one, two or some number of convolutional layers followed by a pooling layer. This structure can then be repeated one or more times. Finally, fully connected layers are often only used at the output end and may be stacked one, two or more deep.\n\u0088\n- Dropout: CNNs have a habit of over\ftting, even with pooling layers. Dropout should be used such as between fully connected layers and perhaps after pooling layers.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "# Project: Predict Sentiment From Movie Reviews\nSentiment analysis is a natural language processing problem where text is understood and the\nunderlying intent is predicted. In this lesson you will discover how you can predict the sentiment\nof movie reviews as either positive or negative in Python using the Keras deep learning library.\nAfter completing this step-by-step tutorial, you will know:\n\u0088 About the IMDB sentiment analysis problem for natural language processing and how to\nload it in Keras.\n- How to use word embedding in Keras for natural language problems.\n- How to develop and evaluate a Multilayer Perceptron model for the IMDB problem.\n- How to develop a one-dimensional convolutional neural network model for the IMDB problem. ", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "import numpy\nfrom keras.datasets import imdb\nfrom matplotlib import pyplot\n# load the dataset\n(X_train, y_train), (X_test, y_test) = imdb.load_data()\nX = numpy.concatenate((X_train, X_test), axis=0)\ny = numpy.concatenate((y_train, y_test), axis=0)# summarize size\n", 
            "cell_type": "code", 
            "metadata": {}, 
            "execution_count": 1, 
            "outputs": [
                {
                    "name": "stderr", 
                    "output_type": "stream", 
                    "text": "Using TensorFlow backend.\n"
                }, 
                {
                    "name": "stdout", 
                    "output_type": "stream", 
                    "text": "Downloading data from https://s3.amazonaws.com/text-datasets/imdb.npz\n16498688/17464789 [===========================>..] - ETA: 0s"
                }
            ]
        }, 
        {
            "source": "Dataset of 25,000 movies reviews from IMDB, labeled by sentiment (positive/negative). Reviews have been preprocessed, and each review is encoded as a sequence of word indexes (integers). For convenience, words are indexed by overall frequency in the dataset, so that for instance the integer \"3\" encodes the 3rd most frequent word in the data. This allows for quick filtering operations such as: \"only consider the top 10,000 most common words, but eliminate the top 20 most common words\".", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "print(\"Training data: \")\nprint(X.shape)\nprint(y.shape)", 
            "cell_type": "code", 
            "metadata": {}, 
            "execution_count": 2, 
            "outputs": [
                {
                    "name": "stdout", 
                    "output_type": "stream", 
                    "text": "Training data: \n(50000,)\n(50000,)\n"
                }
            ]
        }, 
        {
            "source": "df [:]", 
            "cell_type": "code", 
            "metadata": {
                "scrolled": true
            }, 
            "execution_count": 9, 
            "outputs": [
                {
                    "data": {
                        "text/plain": "((array([ list([1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 22665, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 21631, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 19193, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 10311, 8, 4, 107, 117, 5952, 15, 256, 4, 31050, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 12118, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]),\n         list([1, 194, 1153, 194, 8255, 78, 228, 5, 6, 1463, 4369, 5012, 134, 26, 4, 715, 8, 118, 1634, 14, 394, 20, 13, 119, 954, 189, 102, 5, 207, 110, 3103, 21, 14, 69, 188, 8, 30, 23, 7, 4, 249, 126, 93, 4, 114, 9, 2300, 1523, 5, 647, 4, 116, 9, 35, 8163, 4, 229, 9, 340, 1322, 4, 118, 9, 4, 130, 4901, 19, 4, 1002, 5, 89, 29, 952, 46, 37, 4, 455, 9, 45, 43, 38, 1543, 1905, 398, 4, 1649, 26, 6853, 5, 163, 11, 3215, 10156, 4, 1153, 9, 194, 775, 7, 8255, 11596, 349, 2637, 148, 605, 15358, 8003, 15, 123, 125, 68, 23141, 6853, 15, 349, 165, 4362, 98, 5, 4, 228, 9, 43, 36893, 1157, 15, 299, 120, 5, 120, 174, 11, 220, 175, 136, 50, 9, 4373, 228, 8255, 5, 25249, 656, 245, 2350, 5, 4, 9837, 131, 152, 491, 18, 46151, 32, 7464, 1212, 14, 9, 6, 371, 78, 22, 625, 64, 1382, 9, 8, 168, 145, 23, 4, 1690, 15, 16, 4, 1355, 5, 28, 6, 52, 154, 462, 33, 89, 78, 285, 16, 145, 95]),\n         list([1, 14, 47, 8, 30, 31, 7, 4, 249, 108, 7, 4, 5974, 54, 61, 369, 13, 71, 149, 14, 22, 112, 4, 2401, 311, 12, 16, 3711, 33, 75, 43, 1829, 296, 4, 86, 320, 35, 534, 19, 263, 4821, 1301, 4, 1873, 33, 89, 78, 12, 66, 16, 4, 360, 7, 4, 58, 316, 334, 11, 4, 1716, 43, 645, 662, 8, 257, 85, 1200, 42, 1228, 2578, 83, 68, 3912, 15, 36, 165, 1539, 278, 36, 69, 44076, 780, 8, 106, 14, 6905, 1338, 18, 6, 22, 12, 215, 28, 610, 40, 6, 87, 326, 23, 2300, 21, 23, 22, 12, 272, 40, 57, 31, 11, 4, 22, 47, 6, 2307, 51, 9, 170, 23, 595, 116, 595, 1352, 13, 191, 79, 638, 89, 51428, 14, 9, 8, 106, 607, 624, 35, 534, 6, 227, 7, 129, 113]),\n         ...,\n         list([1, 11, 6, 230, 245, 6401, 9, 6, 1225, 446, 86527, 45, 2174, 84, 8322, 4007, 21, 4, 912, 84, 14532, 325, 725, 134, 15271, 1715, 84, 5, 36, 28, 57, 1099, 21, 8, 140, 8, 703, 5, 11656, 84, 56, 18, 1644, 14, 9, 31, 7, 4, 9406, 1209, 2295, 26094, 1008, 18, 6, 20, 207, 110, 563, 12, 8, 2901, 17793, 8, 97, 6, 20, 53, 4767, 74, 4, 460, 364, 1273, 29, 270, 11, 960, 108, 45, 40, 29, 2961, 395, 11, 6, 4065, 500, 7, 14492, 89, 364, 70, 29, 140, 4, 64, 4780, 11, 4, 2678, 26, 178, 4, 529, 443, 17793, 5, 27, 710, 117, 74936, 8123, 165, 47, 84, 37, 131, 818, 14, 595, 10, 10, 61, 1242, 1209, 10, 10, 288, 2260, 1702, 34, 2901, 17793, 4, 65, 496, 4, 231, 7, 790, 5, 6, 320, 234, 2766, 234, 1119, 1574, 7, 496, 4, 139, 929, 2901, 17793, 7750, 5, 4241, 18, 4, 8497, 13164, 250, 11, 1818, 7561, 4, 4217, 5408, 747, 1115, 372, 1890, 1006, 541, 9303, 7, 4, 59, 11027, 4, 3586, 22459]),\n         list([1, 1446, 7079, 69, 72, 3305, 13, 610, 930, 8, 12, 582, 23, 5, 16, 484, 685, 54, 349, 11, 4120, 2959, 45, 58, 1466, 13, 197, 12, 16, 43, 23, 21469, 5, 62, 30, 145, 402, 11, 4131, 51, 575, 32, 61, 369, 71, 66, 770, 12, 1054, 75, 100, 2198, 8, 4, 105, 37, 69, 147, 712, 75, 3543, 44, 257, 390, 5, 69, 263, 514, 105, 50, 286, 1814, 23, 4, 123, 13, 161, 40, 5, 421, 4, 116, 16, 897, 13, 40691, 40, 319, 5872, 112, 6700, 11, 4803, 121, 25, 70, 3468, 4, 719, 3798, 13, 18, 31, 62, 40, 8, 7200, 4, 29455, 7, 14, 123, 5, 942, 25, 8, 721, 12, 145, 5, 202, 12, 160, 580, 202, 12, 6, 52, 58, 11418, 92, 401, 728, 12, 39, 14, 251, 8, 15, 251, 5, 21213, 12, 38, 84, 80, 124, 12, 9, 23]),\n         list([1, 17, 6, 194, 337, 7, 4, 204, 22, 45, 254, 8, 106, 14, 123, 4, 12815, 270, 14437, 5, 16923, 12255, 732, 2098, 101, 405, 39, 14, 1034, 4, 1310, 9, 115, 50, 305, 12, 47, 4, 168, 5, 235, 7, 38, 111, 699, 102, 7, 4, 4039, 9245, 9, 24, 6, 78, 1099, 17, 2345, 16553, 21, 27, 9685, 6139, 5, 29043, 1603, 92, 1183, 4, 1310, 7, 4, 204, 42, 97, 90, 35, 221, 109, 29, 127, 27, 118, 8, 97, 12, 157, 21, 6789, 85010, 9, 6, 66, 78, 1099, 4, 631, 1191, 5, 2642, 272, 191, 1070, 6, 7585, 8, 2197, 70907, 10755, 544, 5, 383, 1271, 848, 1468, 12183, 497, 16876, 8, 1597, 8778, 19280, 21, 60, 27, 239, 9, 43, 8368, 209, 405, 10, 10, 12, 764, 40, 4, 248, 20, 12, 16, 5, 174, 1791, 72, 7, 51, 6, 1739, 22, 4, 204, 131, 9])], dtype=object),\n  array([1, 0, 0, ..., 0, 1, 0])),\n (array([ list([1, 89, 27, 20201, 9289, 17, 199, 132, 5, 4191, 16, 1339, 24, 8, 760, 4, 1385, 7, 4, 22, 1368, 11415, 16, 5149, 17, 1635, 7, 24899, 1368, 9, 4, 1357, 8, 14, 991, 13, 877, 38, 19, 27, 239, 13, 100, 235, 61, 483, 11960, 4, 7, 4, 20, 131, 1102, 72, 8, 14, 251, 27, 1146, 7, 308, 16, 735, 1517, 17, 29, 144, 28, 77, 2305, 18, 12]),\n         list([1, 3452, 7, 16495, 517, 522, 31, 314, 17, 1909, 2046, 11778, 6829, 11424, 83, 4, 2314, 673, 33, 27, 568, 1709, 2923, 32, 4, 189, 22, 11, 975, 4135, 29, 2376, 4, 1287, 7, 4, 16495, 4217, 15, 1435, 455, 1394, 848, 1538, 4031, 96, 145, 11, 4, 204, 6156, 297, 5418, 29, 3044, 4, 1287, 8, 35, 4383, 1609, 121, 15286, 1233, 980, 22025, 2100, 11627, 18273, 34224, 3681, 304, 4, 1287, 145, 8, 41, 1472, 50, 22025, 10737, 20850, 16495, 4364, 34, 2782, 13092, 145, 295, 174, 772, 6, 54788, 18, 274, 961, 90, 145, 8, 4041, 113, 155, 92, 140, 17, 22025, 69, 3205, 16495, 505, 46, 24, 8, 30, 4, 132, 7, 41, 1306, 103, 32, 38, 59, 9560, 90, 11, 6, 297, 7389, 33, 63, 16495, 9, 329, 74, 654, 137, 22025, 304, 6, 4548, 16495, 2949, 27268, 41, 772, 15, 274, 961, 41, 145, 8, 113, 11, 4, 2995, 7, 6, 668, 4217, 1810, 17, 6, 3452, 1082, 181, 8, 30, 1571, 11, 3161, 2350, 28, 8, 157, 295, 8, 79, 8, 6, 6068, 11, 162, 6869, 121, 15286, 1249, 648, 69, 77, 3554, 19, 4, 24774, 887, 8, 4416, 68, 4123, 145, 83, 406, 2350, 4, 2350, 7, 22469, 13174, 3509, 1851, 27, 980, 18288, 10512, 22004, 37, 26, 199, 23, 4, 521, 39, 3408, 1697, 2297, 7, 568, 3864, 30126, 308, 3659, 80, 81, 1780, 10, 10, 526, 34, 10605, 18317, 13, 119, 3452, 7, 16495, 4, 229, 34, 1561, 33562, 9, 87, 253, 55, 702, 728, 545, 441, 2072, 958, 7, 85, 189, 22, 19, 52, 5499, 39, 4, 636, 720, 121, 75, 67, 1655, 19161, 9792, 2377, 39, 4, 2553, 4, 4971, 108, 2281, 79671, 6997, 4626, 10852, 39, 4, 6, 1726, 23, 4903, 890, 201, 488, 4664, 2377, 39, 4, 2195, 3135, 8, 4, 2974, 343, 39, 3452, 7, 5279, 10074, 54, 12, 2360, 19062, 4, 172, 136, 3452, 7, 16495, 115, 304, 410, 615, 63, 9, 43, 17, 73, 50, 26, 775, 7, 31, 2433, 532, 19266, 1994, 15, 2039, 4142, 93, 9032, 6, 171, 153, 908, 12, 152, 306, 1595, 8, 9155, 253, 33, 410, 4, 189, 512, 11, 831, 13, 119, 4, 136, 54, 3509, 18288, 26, 260, 6, 2711, 35646, 731, 2599, 15, 16495, 5224, 29, 166, 163, 22831, 795, 7320, 469, 198, 24, 8, 135, 15, 50, 218, 6, 1543, 52, 22, 11, 50, 17, 73, 88, 50, 91, 434, 9, 167, 18317, 1030, 8, 987, 52, 841, 6, 147, 281, 7, 253, 199, 406, 3161, 732, 7, 105, 26, 1451, 4091, 17, 257, 2162, 2712, 68, 205, 732, 7, 4816, 712, 15, 4, 4951, 7, 5512, 15, 36, 26, 1200, 496, 62, 540, 1203, 2536, 3452, 7, 16495, 9, 87, 18, 4, 91, 173, 47, 15, 194, 352, 6713, 44, 12, 33, 44, 2476, 1782, 1782, 13, 144, 440, 38, 4, 64, 155, 15, 13, 80, 135, 9, 15, 49, 7, 4, 5076, 302, 34, 1842, 26, 6, 117, 3463, 2631, 13, 191, 377, 101, 1683, 139, 11, 3452, 7, 16495, 345, 2670, 4, 22, 152, 9185, 4, 541, 599, 19, 6, 646, 12337, 3681, 5573, 15348, 83, 4472, 393, 11, 3532, 6, 14559, 5003, 3490, 84, 13058, 23, 25769, 7, 3062, 294, 112, 23995, 34, 6, 666, 2832, 6, 3314, 125, 5484, 12318, 998, 24674, 13266, 4, 116, 9, 184, 52, 13092, 17, 16495, 9, 55, 163, 17, 29, 14578, 4, 31, 2433, 46, 13, 82, 40, 4, 139, 19, 22025, 33, 4, 454, 169, 41, 55, 1279, 54, 442, 1658, 32, 15, 7717, 5745, 13, 191, 30, 4, 64, 31, 1348, 13, 1276, 104, 3452, 7, 16495, 9, 6, 777, 22, 964, 722, 39, 380, 8, 1363, 87, 1285, 189, 11, 3215, 4160, 33, 64, 7304, 234, 196, 12, 115, 461, 357, 42, 753, 6, 965, 1640, 7, 1923, 106, 12, 17, 515, 17, 25, 70]),\n         list([1, 1868, 256, 34, 31, 7, 4, 91, 2305, 1507, 7, 4, 236, 2068, 7, 14, 1117, 5, 82, 31, 7, 4, 91, 1020, 1507, 5051, 4686, 46, 7, 2415, 59, 9, 389, 9, 175, 173, 15, 59, 299, 4, 27569, 7466, 9, 4, 3114, 5, 1805, 7, 4, 298, 438, 10, 10, 14347, 3365, 9, 17220, 5, 41, 658, 742, 217, 73, 1391, 34, 530, 284, 5, 82, 735, 2286, 1024, 1487, 3740, 2828, 7, 4, 5072, 255, 47, 6, 254, 58, 19, 4, 17220, 3365, 7, 27, 31, 283, 155, 5, 4846, 27, 5569, 339, 4, 338, 577, 3996, 18644, 29401, 1516, 9477, 47, 96, 99, 76, 873, 7, 41, 57, 2010, 4, 65, 304, 6, 55, 821, 650, 23, 4, 4696, 7, 6, 4069, 11, 14, 20, 4, 64, 577, 47, 8, 276, 41, 113, 23, 1070, 8, 459, 18, 4, 738, 7, 409, 50, 9, 210, 31, 11, 175, 223, 37, 1590, 15, 243, 7, 4756, 3996, 9, 1612, 4, 454, 7, 4, 20, 21, 17, 58, 4097, 59, 630, 56, 1897, 41, 40374, 113, 58, 8774, 8, 41, 223, 59, 60, 1643, 41, 1633, 89, 81, 25, 81, 27, 175, 251, 11, 5, 46, 5, 1337, 8132, 12, 15, 9, 51, 372, 81, 6, 176, 7, 51, 13, 683, 2504, 157, 5359, 75, 2170, 75, 4290, 75, 33747, 75, 3218, 75, 8265, 75, 26, 4, 118, 369, 75, 26, 4, 4727, 2728, 49, 7, 178, 40, 199, 372, 11, 14, 20, 28, 4, 404, 4421, 26, 4, 1987, 26271, 18, 4, 436, 223, 5, 82, 81, 32, 15, 2504, 157, 15, 9, 1868, 3996, 5, 111, 372, 11, 263, 926, 111, 7, 178, 28, 460, 825, 143, 15, 868, 7, 113, 54, 263, 846, 559, 5, 1131, 13, 28, 77, 50, 36, 43, 435, 99, 185, 13, 28, 348, 61, 846, 61, 1216, 21, 13, 115, 2717, 98, 17, 73, 17, 54, 13, 69, 8, 297, 68, 555, 5, 69, 8, 1135, 11, 68, 3730, 14, 20, 6048, 4, 635, 7, 113, 382, 12, 9, 619, 21, 15, 9, 89, 113, 9, 33, 211, 742, 6, 2489, 33, 12762, 9, 2732, 415, 37, 739, 8, 104, 15, 27, 157, 9, 53, 674, 74, 1462, 334, 5, 47, 6, 55, 1300, 5385, 5695, 1841, 4, 372, 11, 27, 113, 29, 9, 24, 565, 195, 8, 5587, 48, 25, 181, 8, 67, 52, 116, 5, 4, 635, 7, 113, 81, 24, 717, 14, 20, 514, 139, 4, 3756, 582, 8, 1868, 24639, 5, 32, 4, 231, 7, 6, 2702, 46, 7, 1912, 2714, 15, 13, 38, 5846, 75, 26, 32, 1912, 18659, 514, 4414, 742, 12, 9, 64, 34, 170, 21979, 15, 25, 923, 15, 25, 26, 66, 170, 4451, 742, 25, 28, 6, 12762, 4421, 21, 121, 9, 129, 483, 10, 10]),\n         ...,\n         list([1, 14, 390, 7, 13634, 1194, 285, 4, 123, 9, 44, 8, 130, 45, 840, 811, 5, 32, 609, 9, 2244, 1888, 11, 14, 390, 4, 13634, 663, 721, 35, 1356, 773, 884, 15658, 8, 4, 10094, 4, 2910, 90, 39, 4, 6953, 5059, 54, 3034, 29, 14948, 11, 17, 6, 11584, 5, 95, 83, 27, 2734, 2391, 29, 14948, 3913, 6, 1513, 63, 484, 6635, 41, 46, 5, 2201, 1098, 41, 95, 14948, 10397, 3913, 51, 9, 317, 7, 4, 1513, 33671, 266, 39, 4, 8543, 5, 560, 4, 45677, 3341, 159, 385, 516, 4, 1042, 21, 112, 4, 671, 7, 31, 12, 43, 6367, 90, 4892, 266, 8, 10606, 4, 85, 2481, 5, 494, 8, 169, 5, 2330, 90, 18, 147, 33671, 2086, 9, 11, 4, 5593, 269, 8, 169, 3636, 54, 5, 10397, 140, 46, 83, 4, 890, 8, 169, 4, 2734, 4, 2734, 659, 98, 103, 68, 985, 4, 4701, 923, 15, 6, 370, 1059, 285, 54, 36, 79, 145, 8, 10094, 269, 8, 985, 4, 1776, 5, 103, 36, 30112, 6, 6, 1718, 825, 36476, 3234, 10397, 1077, 41, 30045, 8, 847, 84, 46, 7, 4, 96, 38, 59, 70, 79, 8, 4, 1550, 21, 36, 79, 68, 8, 522, 5, 10397, 1442, 5, 43, 54, 9, 44, 8, 79, 324, 58, 9, 20746, 8, 121, 36, 721, 884, 15658, 8, 4, 10094, 3682, 11, 5, 14948, 5, 10397, 21, 33671, 9, 131, 11, 4, 5593, 38, 1098, 4, 1042, 5, 14948, 46, 7, 4, 10094, 54, 4892, 417, 266, 29, 191, 10606, 9, 351, 5, 38, 9, 4, 671, 7, 289, 18, 150, 1276, 14, 390, 16, 619, 16, 4, 7, 32, 7, 98, 13, 62, 119, 8, 28, 41, 671, 7, 30045, 13, 66, 92, 104, 33671, 144, 7, 435, 8, 4, 5593, 88, 48, 59, 161, 586, 28, 556, 21, 17674, 961, 4, 671, 7, 289, 295, 174, 5, 146, 654, 19, 4, 3769, 3724]),\n         list([1, 13, 435, 83, 14, 22, 1017, 1383, 18, 6, 2928, 1278, 11, 405, 5228, 7, 4039, 2228, 21, 51, 13, 188, 16, 53, 7, 6, 1162, 3905, 1010, 19, 230, 99, 76, 662, 5, 24, 195, 206, 45, 788, 15, 14, 22, 16, 93, 23, 6, 352, 4, 1979, 26, 6982, 5, 862, 324, 137, 4, 116, 889, 6, 176, 8, 30, 4630, 82, 4, 114, 2679, 23, 6, 3993, 7, 7202, 6, 336, 5, 107, 3197, 15, 2114, 6, 3817, 7, 1818, 103, 880, 49, 11395, 36, 216, 638, 6, 2816, 9135, 34, 6, 185, 250, 5, 41, 8505, 5, 32, 14, 9, 579, 11, 2183, 34, 4, 185, 250, 3880, 21568, 11, 35, 5356, 45, 788, 15, 907, 2393, 5, 1024, 29925, 197, 36, 71, 231, 142, 66, 1621, 21, 466, 94, 118, 2048, 1226, 7, 609, 2527, 9, 43, 99, 357, 8, 1465, 4, 529, 4, 22, 14991, 23, 18, 44, 11064, 234, 5, 91, 7, 12, 3202, 7, 357, 105, 12435, 125, 357, 5, 196, 10168, 414, 4, 64, 52, 155, 13, 28, 8, 135, 44, 4, 22, 9, 19, 6093, 8, 4, 228, 63, 9, 52, 11, 1370, 4, 277, 9, 4, 64, 85, 52, 155, 44, 4, 20, 5, 198, 64, 88, 45, 4, 236, 155, 15, 571, 13, 586, 386, 259, 8780, 5430, 14, 180, 50, 16, 76, 128, 1157, 93, 11, 4, 4039]),\n         list([1, 1252, 54, 13, 435, 8, 67, 14, 20, 33, 4, 5165, 750, 11, 6637, 13, 122, 24, 535, 76, 13, 435, 8, 14, 20, 64, 88, 13, 2626, 1400, 45, 6, 5524, 20, 4092, 30, 52, 18, 6, 462, 95, 13, 1829, 180, 5, 296, 12, 5, 219, 138, 36, 2471, 13370, 31032, 3561, 8, 297, 12164, 13047, 29, 9, 242, 31, 7, 4, 31524, 493, 23, 4, 194, 268, 76, 433, 11, 61, 652, 74, 2281, 42, 1655, 5, 47, 31, 194, 3079, 8, 85, 102, 15, 11069, 72, 8, 6, 189, 20, 12, 287, 12164, 13047, 17, 294, 37, 9, 406, 29, 47, 6, 483, 57, 551, 89, 2509, 5, 948, 12, 9, 29, 764, 1460, 142, 15, 1655, 115, 127, 42, 739, 8, 123, 29, 764, 8534, 5, 1742, 151, 174, 199, 7, 98, 2140, 63, 25, 80, 1495, 48, 25, 67, 4, 20, 32, 11, 32, 6, 275, 585, 11, 61, 652, 74, 111, 7416, 5, 12, 770, 72, 11, 6, 171, 771, 17, 11, 37, 1452, 11, 4, 130])], dtype=object),\n  array([1, 1, 1, ..., 1, 0, 1])))"
                    }, 
                    "execution_count": 9, 
                    "metadata": {}, 
                    "output_type": "execute_result"
                }
            ]
        }, 
        {
            "source": "# Word Embeddings\nA recent breakthrough in the \feld of natural language processing is called word embedding. This\nis a technique where words are encoded as real-valued vectors in a high dimensional space, where\nthe similarity between words in terms of meaning translates to closeness in the vector space.\nDiscrete words are mapped to vectors of continuous numbers. This is useful when working with\nnatural language problems with neural networks as we require numbers as input values.\nKeras provides a convenient way to convert positive integer representations of words into a\nword embedding by an Embedding layer4. The layer takes arguments that de\fne the mapping\nincluding the maximum number of expected words also called the vocabulary size (e.g. the\nlargest integer value that will be seen as an input). The layer also allows you to specify the\ndimensionality for each word vector, called the output dimension.\n\nKeras provides a convenient way to convert positive integer representations of words into a\nword embedding by an Embedding layer4. The layer takes arguments that de\fne the mapping\nincluding the maximum number of expected words also called the vocabulary size (e.g. the\nlargest integer value that will be seen as an input). The layer also allows you to specify the\ndimensionality for each word vector, called the output dimension.\nWe would like to use a word embedding representation for the IMDB dataset. Let's say\nthat we are only interested in the \frst 5,000 most used words in the dataset. Therefore our vocabulary size will be 5,000. We can choose to use a 32-dimensional vector to represent each\nword. Finally, we may choose to cap the maximum review length at 500 words, truncating\nreviews longer than that and padding reviews shorter than that with 0 values. We would load\nthe IMDB dataset as follows:", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "", 
            "cell_type": "code", 
            "metadata": {
                "collapsed": true
            }, 
            "execution_count": null, 
            "outputs": []
        }
    ], 
    "metadata": {
        "language_info": {
            "pygments_lexer": "ipython2", 
            "codemirror_mode": {
                "version": 2, 
                "name": "ipython"
            }, 
            "mimetype": "text/x-python", 
            "name": "python", 
            "file_extension": ".py", 
            "version": "2.7.11", 
            "nbconvert_exporter": "python"
        }, 
        "kernelspec": {
            "language": "python", 
            "display_name": "Python 2 with Spark 2.1", 
            "name": "python2-spark21"
        }
    }, 
    "nbformat_minor": 1
}