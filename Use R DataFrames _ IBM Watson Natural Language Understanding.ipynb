{
    "metadata": {
        "language_info": {
            "file_extension": ".r", 
            "name": "R", 
            "mimetype": "text/x-r-source", 
            "version": "3.3.2", 
            "pygments_lexer": "r", 
            "codemirror_mode": "r"
        }, 
        "kernelspec": {
            "name": "r-spark21", 
            "language": "R", 
            "display_name": "R with Spark 2.1"
        }
    }, 
    "nbformat": 4, 
    "nbformat_minor": 1, 
    "cells": [
        {
            "source": "<div><img src=\"https://www.ibm.com/blogs/bluemix/wp-content/uploads/2017/02/NLU.png\", width=270, height=270, align = 'right'> \n\n<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/5/51/IBM_logo.svg/640px-IBM_logo.svg.png\", width = 90, height = 90, align = 'right', style=\"margin:0px 25px\"></div>\n\n# Retrieve DataFrames to visualize data from IBM Watson Natural Language Understanding\n\nIn this R notebook, you'll use IBM Watson Natural Language Understanding (NLU) to analyze keywords from the websites of the Fortune 100 companies. You'll convert the results of NLU into a set of R DataFrames that you can easily analyze in a notebook. Then you'll create a visual representation of the keywords. \n\nData scientists use NLU to uncover insights about sentiment and emotion from structured and unstructured data and to analyze text to extract metadata, such as concepts, entities, keywords, categories, relations, and semantic roles. NLU returns both the overall sentiment and emotion for the whole document and the specific sentiment and emotion for each of the keywords in the text, for deeper analysis.\n\nTo start with that tutorial, see [Visualize a customer base with Watson NLU](#visualize). To read a little more about the technology and some of the other fun things you can do, see [Getting personal about Watson Natural Language Understanding](#about) and [Using R & Watson NLU](#using_r). \n\nThis notebook runs on R with Spark 2.0.", 
            "metadata": {}, 
            "cell_type": "markdown"
        }, 
        {
            "source": "## Table of contents\n\n1.  [Getting personal about Watson Natural Language Understanding](#about)<br>\n    1.1  [What data do we get from Watson NLU?](#what_data)\n\n2.  [Using R & Watson NLU](#using_r)<br>\n    2.1  [Using the `httr` and `jsonlite` packages](#httr)<br>\n    2.2  [Functional access to Watson NLU](#functiondetails) <br>\n    2.3  [Understand the `watsonNLUtoDF()` package](#watsonnlutodf)<br>\n\n3.  [Visualize a customer base with Watson NLU](#visualize)<br>\n    3.1  [Load the customer data](#visualize1) <br>\n    3.2  [Shape the data for the NLU function](#visualize2)<br>\n    3.3  [Send customersDF to Watson](#visualize3)<br>\n    3.4  [Concatenate the concepts and keywords extracted from Watson](#visualize4)<br>\n    3.5  [Format the Text for a Word Cloud](#visualize5)<br>\n    3.6  [Visualize with the Brunel library](#visualize6)<br>\n\n[Summary and next steps](#summary)", 
            "metadata": {}, 
            "cell_type": "markdown"
        }, 
        {
            "source": "<a id='about'></a>\n## 1. Getting personal about Watson Natural Language Understanding \n\nThe first time I tested Watson NLU a huge grin spread across my face. For me it was one another one of those moments where technology inspired awe - sort of like when I played my first PC game as a kid in 1990 or when I saw the iPhone in 2006.  So what exactly is Watson NLU? \n\n> *With a sophisticated suite of natural language processing capabilities, NLU can analyze text and extract meta-data from unstructured content such as concepts, entities, keywords, categories, sentiment, emotion, relations, semantic roles. You can also customize the text analysis with NLU for linguistic nuances specific to your domain or industry (such as entities and relations) with custom models developed using Watson Knowledge Studio. With customization, you can further improve the accuracy of meta-data extraction. Whether it is social media monitoring, content recommendation, or advertising optimization, NLU can be easily put to use for extracting the hard to find insights from unstructured content.*  \n\n> Source: __[IBM Bluemix Blog](https://www.ibm.com/blogs/bluemix/2017/02/hello-nlu/)__\n\nIn other words, the NLU service allows you to send unstructured data to Watson and have it return a rich set of structured data.  For example, you can send Watson a block of text and it will understand the information contained therein. Alternatively, you can send a URL and extract all the information from it.\n\nOk, sounds kinda cool, but what's the 'wow' factor?  Read on.\n\n<a id='what_data'></a>\n### 1.1 What data do we get from Watson NLU?\n\nThe easiest way to get a sense of what NLU does is to __[try the demo](https://natural-language-understanding-demo.mybluemix.net/)__.  So, go there and come back after you've played around with submitting different URLs and text to the service.  \n\nBack?  Are you impressed yet?  You must be!  As you saw, we get detailed information about the concepts, sentiment, and categorization of the data we send to Watson.  \n\n<a id='using_r'></a>\n## 2. Using R and Watson NLU\n\nI wanted to work with the data from NLU in R but there didn't seem to be many resources available online.  Rather than work directly with the JSON returned by the service, I decided to write a function - `watsonNLUtoDF()` - that converts NLU results from JSON into a list of R DataFrames.  To do so, I had to use two excellent R packages.\n\n<a id='httr'></a>\n### 2.1 The `httr` and `jsonlite` packages\n\nThe `httr` package is one of the many packages for R that is written by Hadley Wickham. It provides access to `curl` functionality from inside of R, and its simplicity is classic Hadley. For example, if to run `POST()` or `GET()` using a URL is easy. You must include authentication and JSON-structured data in the `POST()` to Watson NLU:\n\n> `> POST(URL, authenticate(username, password), body = toJSON(list(features)))`\n\nYou'll notice the `toJSON()` function in there.  That comes from the `jsonlite` package, which offers excellent support for converting R objects to and from JSON.  As you can see this came in handy when I needed to send JSON to Watson NLU.  It is also essential in parsing the response from Watson into R DataFrames. \n\nThese two packages let me access Watson NLU from R, but I still needed a way to access the API in a more programmatic, scalable fashion. That's why I wrote the function.", 
            "metadata": {}, 
            "cell_type": "markdown"
        }, 
        {
            "source": "<a id='functiondetails'></a>\n### 2.2 Functional access to Watson NLU\n\nYou need to define the function to access NLU and understand its usage and arguments. You can skip ahead and look at the [function documentation](#watsonnlutodf). But before you can run the function, you need to get NLU credentials and import packages.\n\nSign up for NLU and add your NLU credentials:\n1. Create a service for [Natural Language Understanding (NLU)](https://www.ibm.com/watson/developercloud/natural-language-understanding.html). \n1. Insert the username and password values for your NLU service in the following cell. \n1. Run the cell.", 
            "metadata": {}, 
            "cell_type": "markdown"
        }, 
        {
            "execution_count": 1, 
            "source": "# The code was removed by DSX for sharing.", 
            "metadata": {
                "collapsed": true
            }, 
            "outputs": [], 
            "cell_type": "code"
        }, 
        {
            "source": "Install and import the necessary packages:", 
            "metadata": {}, 
            "cell_type": "markdown"
        }, 
        {
            "execution_count": 2, 
            "source": "# This notebook uses version 2.3 of Brunel. If the version changes in the future, the visualization may not work and you will need \n# to update the version number in the code. \n \ninstall.packages('tm')\ninstall.packages(\"devtools\")\ndevtools::install_github(\"Brunel-Visualization/Brunel\", subdir=\"R\", ref=\"v2.3\", force=TRUE)\nlibrary(brunel)\nlibrary(tm)\nlibrary(httr)\nlibrary(jsonlite)", 
            "metadata": {}, 
            "outputs": [
                {
                    "name": "stderr", 
                    "output_type": "stream", 
                    "text": "Installing package into \u2018/gpfs/global_fs01/sym_shared/YPProdSpark/user/sc3e-53554f95eddadf-4e28db014a7c/R/libs\u2019\n(as \u2018lib\u2019 is unspecified)\nInstalling package into \u2018/gpfs/global_fs01/sym_shared/YPProdSpark/user/sc3e-53554f95eddadf-4e28db014a7c/R/libs\u2019\n(as \u2018lib\u2019 is unspecified)\nWarning message in install.packages(\"devtools\"):\n\u201cinstallation of package \u2018devtools\u2019 had non-zero exit status\u201dDownloading GitHub repo Brunel-Visualization/Brunel@v2.3\nfrom URL https://api.github.com/repos/Brunel-Visualization/Brunel/zipball/v2.3\nInstalling brunel\nInstalling 1 package: jsonlite\nInstalling package into \u2018/gpfs/global_fs01/sym_shared/YPProdSpark/user/sc3e-53554f95eddadf-4e28db014a7c/R/libs\u2019\n(as \u2018lib\u2019 is unspecified)\nWarning message in utils::install.packages(pkgs, repos = repos, type = type, dependencies = dependencies, :\n\u201cinstallation of package \u2018jsonlite\u2019 had non-zero exit status\u201d'/usr/local/src/bluemix_jupyter_bundle/R/lib64/R/bin/R' --no-site-file  \\\n  --no-environ --no-save --no-restore --quiet CMD INSTALL  \\\n  '/gpfs/global_fs01/sym_shared/YPProdSpark/user/sc3e-53554f95eddadf-4e28db014a7c/notebook/tmp/RtmpQmCd2q/devtools55692a2bc741/Brunel-Visualization-Brunel-451378a/R'  \\\n  --library='/gpfs/global_fs01/sym_shared/YPProdSpark/user/sc3e-53554f95eddadf-4e28db014a7c/R/libs'  \\\n  --install-tests \n\nLoading required package: NLP\n\nAttaching package: \u2018httr\u2019\n\nThe following object is masked from \u2018package:NLP\u2019:\n\n    content\n\n"
                }
            ], 
            "cell_type": "code"
        }, 
        {
            "source": "Define the function to retrieve DataFrames from the Watson API:", 
            "metadata": {}, 
            "cell_type": "markdown"
        }, 
        {
            "execution_count": 3, 
            "source": "watsonNLUtoDF <- function(data, username, password, verbose = F, language = 'en') {\n  \n  ## Url for Watson NLU service on Bluemix used to POST (send) content to the service to have it analyzed.  \n  ## For more details: https://www.ibm.com/watson/developercloud/natural-language-understanding/api/v1/#post-analyze \n  base_url <- \"https://gateway.watsonplatform.net/natural-language-understanding/api/v1/analyze?version=2017-02-27\"\n  \n    ## Initialize Empty DataFrames\n  conceptsDF <- data.frame()\n  keywordsDF <- data.frame()\n  sentimentDF <- data.frame()\n  categoriesDF <- data.frame()\n  analyzedTextDF <- data.frame()\n  \n  ## Loop over each id, identify the type and send the value to Watson\n  for (i in 1:nrow(data)){\n    try({\n      \n      id <- data$id[i]\n      value <- data$value[i]\n      \n      ## Define the JSON payload for NLU\n      body <- list(api_endpoint = value, \n                   features = list(\n                     categories = {},\n                     concepts = {},\n                     keywords = {},\n                     sentiment = {}),\n                   language = language,\n                   return_analyzed_text = TRUE)\n      \n      ## Provide the correct type for each id\n      names(body)[1] <- data$type[i]\n      \n      if(verbose == T){\n      print(paste(\"Sending\", data$type[i], \"for\", id, \"to Watson NLU...\"))\n      }\n      \n      ## Hit the API and return JSON\n      watsonResponse <- POST(base_url,\n                             content_type_json(),\n                             authenticate(username, password, type = \"basic\"),\n                             body = toJSON(body, auto_unbox = T)) \n\n        ## Parse JSON into DataFrames\n      concepts <- data.frame(id = id, \n                             fromJSON(toJSON(content(watsonResponse), pretty = T), flatten = T)$concepts,\n                             stringsAsFactors = F)\n\n      keywords <- data.frame(id = id, \n                             fromJSON(toJSON(content(watsonResponse), pretty = T), flatten = T)$keywords,\n                             stringsAsFactors = F)\n      \n      sentiment <- data.frame(id = id, \n                             fromJSON(toJSON(content(watsonResponse), pretty = T), flatten = T)$sentiment,\n                             stringsAsFactors = F)\n      \n      categories <- data.frame(id = id,\n                               fromJSON(toJSON(content(watsonResponse), pretty = T), flatten = T)$categories,\n                               stringsAsFactors = F)\n      \n      analyzedText <- data.frame(id = id,\n                                 fromJSON(toJSON(content(watsonResponse), pretty = T), flatten = T)$analyzed_text,\n                                 stringsAsFactors = F)\n      \n      \n      ## Append results to output DataFrames\n      conceptsDF <- rbind(conceptsDF, concepts)\n      keywordsDF <- rbind(keywordsDF, keywords)\n      sentimentDF <- rbind(sentimentDF, sentiment)\n      categoriesDF <- rbind(categoriesDF, categories)\n      analyzedTextDF <- rbind(analyzedTextDF, analyzedText)\n      \n      if(verbose == T) {\n      print(paste(\"Iteration\", i, \"of\", nrow(data), \"complete.\"))\n      }\n    })\n  }\n  resultsList <- list(conceptsDF, keywordsDF, sentimentDF, categoriesDF, analyzedTextDF, watsonResponse)\n  names(resultsList) <- c(\"conceptsDF\", \"keywordsDF\", \"sentimentDF\", \"categoriesDF\", \"analyzedTextDF\", \"response\")\n  return(resultsList)\n}", 
            "metadata": {
                "collapsed": true
            }, 
            "outputs": [], 
            "cell_type": "code"
        }, 
        {
            "source": "<a id='watsonnlutodf'></a>\n### 2.3 Understand the `watsonNLUtoDF()` function\n\n#### Usage\n > `watsonNLUtoDF(data, username, password, verbose = F, language = 'en')`\n\n#### Arguments\n > - **data:** *DataFrame* with 3 columns: \n     - `id` *(string)* \n     - `type` *(string)*, must be one of `url` or `text` - think of this as which API endpoint you want to submit to. \n     - `value` *(string)*, contains the data you want to send.\n     \n > * **username:** *string*.  User name for the NLU service on Bluemix.\n \n > * **password:** *string*.  Password for the NLU service on Bluemix.\n \n > * **verbose**: *boolean*.  Print messages showing progress. Defaults to `F`.\n \n > * **language**: *string*.  Default is English. [See the API docs](https://www.ibm.com/watson/developercloud/doc/natural-language-understanding/#supported-languages) for available options.\n \n#### Value\n\n > A *list* of five dataframes extracted from the service:\n     1. conceptsDF\n     2. keywordsDF\n     3. sentimentDF\n     4. categoriesDF\n     5. analyzedTextDF\n  \n#### Example:\nCreate a DataFrame with `id`, `type`, and `value` columns that contains a row with a URL and a row with text:", 
            "metadata": {}, 
            "cell_type": "markdown"
        }, 
        {
            "execution_count": 4, 
            "source": "df <- data.frame(id = c(\"Seattle Seahawks\", \"Seattle Sounders\"), \n                 type = c(\"url\", \"text\"),\n                 value = c(\"www.seahawks.com\", \n                           \"From Wikipedia.org: Seattle Sounders FC is an American professional soccer club based \n                           in Seattle, Washington. The Sounders compete as a member of the Western Conference of \n                           Major League Soccer (MLS) and are the league's current defending champions, having won\n                           the 2016 MLS Cup. The club was established on November 13, 2007, and began play in 2009\n                           as an MLS expansion team. The Sounders are the third Seattle soccer club to share the \n                           Sounders name being part of a legacy which traces back to the original team of the NASL\n                           in 1974.\"),\n                 stringsAsFactors = F)\n\nhead(df)", 
            "metadata": {
                "scrolled": true
            }, 
            "outputs": [
                {
                    "metadata": {}, 
                    "output_type": "display_data", 
                    "data": {
                        "text/latex": "\\begin{tabular}{r|lll}\n id & type & value\\\\\n\\hline\n\t Seattle Seahawks                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             & url                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          & www.seahawks.com                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            \\\\\n\t Seattle Sounders                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             & text                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         & From Wikipedia.org: Seattle Sounders FC is an American professional soccer club based \n                           in Seattle, Washington. The Sounders compete as a member of the Western Conference of \n                           Major League Soccer (MLS) and are the league's current defending champions, having won\n                           the 2016 MLS Cup. The club was established on November 13, 2007, and began play in 2009\n                           as an MLS expansion team. The Sounders are the third Seattle soccer club to share the \n                           Sounders name being part of a legacy which traces back to the original team of the NASL\n                           in 1974.\\\\\n\\end{tabular}\n", 
                        "text/html": "<table>\n<thead><tr><th scope=col>id</th><th scope=col>type</th><th scope=col>value</th></tr></thead>\n<tbody>\n\t<tr><td>Seattle Seahawks                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            </td><td>url                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         </td><td>www.seahawks.com                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            </td></tr>\n\t<tr><td>Seattle Sounders                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            </td><td>text                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        </td><td>From Wikipedia.org: Seattle Sounders FC is an American professional soccer club based \n                           in Seattle, Washington. The Sounders compete as a member of the Western Conference of \n                           Major League Soccer (MLS) and are the league's current defending champions, having won\n                           the 2016 MLS Cup. The club was established on November 13, 2007, and began play in 2009\n                           as an MLS expansion team. The Sounders are the third Seattle soccer club to share the \n                           Sounders name being part of a legacy which traces back to the original team of the NASL\n                           in 1974.</td></tr>\n</tbody>\n</table>\n", 
                        "text/plain": "  id               type\n1 Seattle Seahawks url \n2 Seattle Sounders text\n  value                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       \n1 www.seahawks.com                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            \n2 From Wikipedia.org: Seattle Sounders FC is an American professional soccer club based \\n                           in Seattle, Washington. The Sounders compete as a member of the Western Conference of \\n                           Major League Soccer (MLS) and are the league's current defending champions, having won\\n                           the 2016 MLS Cup. The club was established on November 13, 2007, and began play in 2009\\n                           as an MLS expansion team. The Sounders are the third Seattle soccer club to share the \\n                           Sounders name being part of a legacy which traces back to the original team of the NASL\\n                           in 1974."
                    }
                }
            ], 
            "cell_type": "code"
        }, 
        {
            "source": "Run the `watsonNLUtoDF` function on the DataFrame and specify to return a DataFrame of concepts and a DataFrame of categories:", 
            "metadata": {}, 
            "cell_type": "markdown"
        }, 
        {
            "execution_count": 5, 
            "source": "## Send properly formatted DataFrame with credentials to Watson\nresponseList <- watsonNLUtoDF(df, username, password, verbose = T)\n\nhead(responseList$conceptsDF)\nhead(responseList[4]) ## 'categories'", 
            "metadata": {}, 
            "outputs": [
                {
                    "name": "stdout", 
                    "output_type": "stream", 
                    "text": "[1] \"Sending url for Seattle Seahawks to Watson NLU...\"\n[1] \"Iteration 1 of 2 complete.\"\n[1] \"Sending text for Seattle Sounders to Watson NLU...\"\n[1] \"Iteration 2 of 2 complete.\"\n"
                }, 
                {
                    "metadata": {}, 
                    "output_type": "display_data", 
                    "data": {
                        "text/latex": "\\begin{tabular}{r|llll}\n id & text & relevance & dbpedia\\_resource\\\\\n\\hline\n\t Seattle Seahawks                                         & National Football League                                 & 0.9576                                                   & http://dbpedia.org/resource/National\\_Football\\_League\\\\\n\t Seattle Seahawks                                   & Kansas City Chiefs                                 & 0.545                                              & http://dbpedia.org/resource/Kansas\\_City\\_Chiefs\\\\\n\t Seattle Seahawks                               & Seattle Seahawks                               & 0.5177                                         & http://dbpedia.org/resource/Seattle\\_Seahawks\\\\\n\t Seattle Seahawks                           & Pete Carroll                               & 0.4893                                     & http://dbpedia.org/resource/Pete\\_Carroll\\\\\n\t Seattle Seahawks                                                               & National Football League exhibition season                                     & 0.3404                                                                         & http://dbpedia.org/resource/National\\_Football\\_League\\_exhibition\\_season\\\\\n\t Seattle Seahawks                            & Season ticket                               & 0.3399                                      & http://dbpedia.org/resource/Season\\_ticket\\\\\n\\end{tabular}\n", 
                        "text/html": "<table>\n<thead><tr><th scope=col>id</th><th scope=col>text</th><th scope=col>relevance</th><th scope=col>dbpedia_resource</th></tr></thead>\n<tbody>\n\t<tr><td>Seattle Seahawks                                    </td><td>National Football League                            </td><td>0.9576                                              </td><td>http://dbpedia.org/resource/National_Football_League</td></tr>\n\t<tr><td>Seattle Seahawks                              </td><td>Kansas City Chiefs                            </td><td>0.545                                         </td><td>http://dbpedia.org/resource/Kansas_City_Chiefs</td></tr>\n\t<tr><td>Seattle Seahawks                            </td><td>Seattle Seahawks                            </td><td>0.5177                                      </td><td>http://dbpedia.org/resource/Seattle_Seahawks</td></tr>\n\t<tr><td>Seattle Seahawks                        </td><td>Pete Carroll                            </td><td>0.4893                                  </td><td>http://dbpedia.org/resource/Pete_Carroll</td></tr>\n\t<tr><td>Seattle Seahawks                                                      </td><td>National Football League exhibition season                            </td><td>0.3404                                                                </td><td>http://dbpedia.org/resource/National_Football_League_exhibition_season</td></tr>\n\t<tr><td>Seattle Seahawks                         </td><td>Season ticket                            </td><td>0.3399                                   </td><td>http://dbpedia.org/resource/Season_ticket</td></tr>\n</tbody>\n</table>\n", 
                        "text/plain": "  id               text                                       relevance\n1 Seattle Seahawks National Football League                   0.9576   \n2 Seattle Seahawks Kansas City Chiefs                         0.545    \n3 Seattle Seahawks Seattle Seahawks                           0.5177   \n4 Seattle Seahawks Pete Carroll                               0.4893   \n5 Seattle Seahawks National Football League exhibition season 0.3404   \n6 Seattle Seahawks Season ticket                              0.3399   \n  dbpedia_resource                                                      \n1 http://dbpedia.org/resource/National_Football_League                  \n2 http://dbpedia.org/resource/Kansas_City_Chiefs                        \n3 http://dbpedia.org/resource/Seattle_Seahawks                          \n4 http://dbpedia.org/resource/Pete_Carroll                              \n5 http://dbpedia.org/resource/National_Football_League_exhibition_season\n6 http://dbpedia.org/resource/Season_ticket                             "
                    }
                }, 
                {
                    "metadata": {}, 
                    "output_type": "display_data", 
                    "data": {
                        "text/latex": "\\textbf{\\$categoriesDF} = \\begin{tabular}{r|lll}\n id & score & label\\\\\n\\hline\n\t Seattle Seahawks & 0.9999           & /sports/football\\\\\n\t Seattle Seahawks                       & 0.3846                                 & /business and industrial/business news\\\\\n\t Seattle Seahawks                                             & 0.2957                                                       & /technology and computing/internet technology/social network\\\\\n\t Seattle Sounders & 0.7794           & /sports/soccer  \\\\\n\t Seattle Sounders   & 0.3538             & /sports/gymnastics\\\\\n\t Seattle Sounders & 0.2107           & /real estate    \\\\\n\\end{tabular}\n", 
                        "text/html": "<strong>$categoriesDF</strong> = <table>\n<thead><tr><th scope=col>id</th><th scope=col>score</th><th scope=col>label</th></tr></thead>\n<tbody>\n\t<tr><td>Seattle Seahawks</td><td>0.9999          </td><td>/sports/football</td></tr>\n\t<tr><td>Seattle Seahawks                      </td><td>0.3846                                </td><td>/business and industrial/business news</td></tr>\n\t<tr><td>Seattle Seahawks                                            </td><td>0.2957                                                      </td><td>/technology and computing/internet technology/social network</td></tr>\n\t<tr><td>Seattle Sounders</td><td>0.7794          </td><td>/sports/soccer  </td></tr>\n\t<tr><td>Seattle Sounders  </td><td>0.3538            </td><td>/sports/gymnastics</td></tr>\n\t<tr><td>Seattle Sounders</td><td>0.2107          </td><td>/real estate    </td></tr>\n</tbody>\n</table>\n", 
                        "text/plain": "$categoriesDF\n                id  score\n1 Seattle Seahawks 0.9999\n2 Seattle Seahawks 0.3846\n3 Seattle Seahawks 0.2957\n4 Seattle Sounders 0.7794\n5 Seattle Sounders 0.3538\n6 Seattle Sounders 0.2107\n                                                         label\n1                                             /sports/football\n2                       /business and industrial/business news\n3 /technology and computing/internet technology/social network\n4                                               /sports/soccer\n5                                           /sports/gymnastics\n6                                                 /real estate\n"
                    }
                }
            ], 
            "cell_type": "code"
        }, 
        {
            "source": "The first returned DataFrame shows which concepts are most important. The second returned DataFrame shows which categories best describe the text. Watson is very confident that the text is about football! ", 
            "metadata": {}, 
            "cell_type": "markdown"
        }, 
        {
            "source": "<a id='visualize'></a>\n\n## 3. Visualize a customer base with Watson NLU\n\nAt this point, you should have a good idea of what the NLU service provides and how you've accessed it in R. Now have a little fun and visualize some output.\n\nThe data science goal of this notebook is understanding market segmentation across a customer base.  **Can you use an AI engine to better understand and classify both existing and potential customers?  Watson is well suited for this task!**  Use the `watsonNLUtoDF` function to send Watson a DataFrame full of company names and a mix of their URLs and text descriptions. Then  build a word cloud with the concepts and keywords that are returned.", 
            "metadata": {}, 
            "cell_type": "markdown"
        }, 
        {
            "source": "<a id='visualize1'></a>\n### 3.1  Load the customer data\nDownload the data set from the DSX community and load it into a DataFrame.\n\nTo load the data:\n1. Go to the [Fortune 100 companies data set](https://apsportal.ibm.com/exchange/public/entry/view/4d26cd0dd964734bc23c6475a8dc454b) on the DSX Community. \n2. Click the download icon and save the data set as .csv file to your computer.  \n3. Load the `fortune100.csv` file into your notebook. Click the **Find and Add Data** icon on the notebook action bar. Drop the file into the box or browse to select the file. The file is loaded to your object storage and appears in the Data Assets section of the project. For more information, see <a href=\"https://datascience.ibm.com/docs/content/analyze-data/load-and-access-data.html\" target=\"_blank\" rel=\"noopener noreferrer\">Load and access data</a>.\n4. To load the data from the `fortune100.csv` file into a R DataFrame, click in the next code cell and select **Insert to code > Insert R DataFrame** under the file name.\n5. Rename the two instances of `df.data.x` to `customersDF` in the last two lines.\n6. Run the cell.", 
            "metadata": {
                "collapsed": true
            }, 
            "cell_type": "markdown"
        }, 
        {
            "execution_count": null, 
            "source": "", 
            "metadata": {}, 
            "outputs": [], 
            "cell_type": "code"
        }, 
        {
            "execution_count": 6, 
            "source": "# Load data using Insert to code > Insert R DataFrame\n", 
            "metadata": {}, 
            "outputs": [
                {
                    "name": "stderr", 
                    "output_type": "stream", 
                    "text": "Loading required package: RCurl\nLoading required package: bitops\n\nAttaching package: \u2018RCurl\u2019\n\nThe following object is masked from \u2018package:SparkR\u2019:\n\n    base64\n\n"
                }, 
                {
                    "metadata": {}, 
                    "output_type": "display_data", 
                    "data": {
                        "text/latex": "\\begin{tabular}{r|lll}\n id & type & value\\\\\n\\hline\n\t Walmart                          & url                              & http://www.walmart.com          \\\\\n\t Exxon Mobil                      & url                              & http://www.exxonmobil.com       \\\\\n\t Apple                            & url                              & http://www.apple.com            \\\\\n\t Berkshire Hathaway               & url                              & http://www.berkshirehathaway.com\\\\\n\t McKesson                         & url                              & http://www.mckesson.com         \\\\\n\t UnitedHealth Group               & url                              & http://www.unitedhealthgroup.com\\\\\n\\end{tabular}\n", 
                        "text/html": "<table>\n<thead><tr><th scope=col>id</th><th scope=col>type</th><th scope=col>value</th></tr></thead>\n<tbody>\n\t<tr><td>Walmart                         </td><td>url                             </td><td>http://www.walmart.com          </td></tr>\n\t<tr><td>Exxon Mobil                     </td><td>url                             </td><td>http://www.exxonmobil.com       </td></tr>\n\t<tr><td>Apple                           </td><td>url                             </td><td>http://www.apple.com            </td></tr>\n\t<tr><td>Berkshire Hathaway              </td><td>url                             </td><td>http://www.berkshirehathaway.com</td></tr>\n\t<tr><td>McKesson                        </td><td>url                             </td><td>http://www.mckesson.com         </td></tr>\n\t<tr><td>UnitedHealth Group              </td><td>url                             </td><td>http://www.unitedhealthgroup.com</td></tr>\n</tbody>\n</table>\n", 
                        "text/plain": "  id                 type value                           \n1 Walmart            url  http://www.walmart.com          \n2 Exxon Mobil        url  http://www.exxonmobil.com       \n3 Apple              url  http://www.apple.com            \n4 Berkshire Hathaway url  http://www.berkshirehathaway.com\n5 McKesson           url  http://www.mckesson.com         \n6 UnitedHealth Group url  http://www.unitedhealthgroup.com"
                    }
                }
            ], 
            "cell_type": "code"
        }, 
        {
            "source": "<a id='visualize2'></a>\n### 3.2 Shape the data for the NLU function\n\nThe DataFrame already has correctly named columns of `id`, `type`, and `value`. Make sure that all the column types are strings:\n\n1. Copy the value of the `file` argument from the `read.csv` function in the previous cell and replace the text `YOUR_VALUE`. For example: <br>\n    `file = getObjectStorageFileWithCredentials_xxxxxxxxx(\"<your project>\", \"fortune100.csv\")`\n1. Run the cell.", 
            "metadata": {}, 
            "cell_type": "markdown"
        }, 
        {
            "execution_count": 7, 
            "source": "# Copy and past the read.csv command from the cell above, adding 'stringsAsFactors = F' as an additional parameter \n# to ensure that column types are returned as strings\n#   ex: customersDF <-  read.csv(file = getObjectStorageFileWithCredentials_xxxxxxxxx(\"<your project>\", \"fortune100.csv\"), stringsAsFactors = F)\n\ncustomersDF <-  read.csv(file = YOUR VALUE), stringsAsFactors = F)\n\nstr(customersDF)", 
            "metadata": {}, 
            "outputs": [
                {
                    "name": "stdout", 
                    "output_type": "stream", 
                    "text": "'data.frame':\t100 obs. of  3 variables:\n $ id   : chr  \"Walmart\" \"Exxon Mobil\" \"Apple\" \"Berkshire Hathaway\" ...\n $ type : chr  \"url\" \"url\" \"url\" \"url\" ...\n $ value: chr  \"http://www.walmart.com\" \"http://www.exxonmobil.com\" \"http://www.apple.com\" \"http://www.berkshirehathaway.com\" ...\n"
                }
            ], 
            "cell_type": "code"
        }, 
        {
            "source": "Looks good!  \n\n<a id='visualize3'></a>\n### 3.3 Send `customersDF`  to Watson \nRun the `watsonNLUtoDF` function to send the customersDF DataFrame to Watson NLU:", 
            "metadata": {
                "scrolled": true
            }, 
            "cell_type": "markdown"
        }, 
        {
            "execution_count": 8, 
            "source": "responseList <- watsonNLUtoDF(customersDF, username, password)", 
            "metadata": {
                "collapsed": true
            }, 
            "outputs": [], 
            "cell_type": "code"
        }, 
        {
            "source": "<a id='visualize4'></a>\n### 3.4 Concatenate the concepts and keywords extracted from Watson \nNow concatenate the resulting concepts and keywords lists into a customerDocument DataFrame:", 
            "metadata": {}, 
            "cell_type": "markdown"
        }, 
        {
            "execution_count": 9, 
            "source": "customerDocument <- paste(responseList$concepts$text, responseList$keywords$text, sep = \" \", collapse = \" \")", 
            "metadata": {
                "collapsed": true
            }, 
            "outputs": [], 
            "cell_type": "code"
        }, 
        {
            "source": "<a id='visualize5'></a>\n### 3.5 Format the Text for a Word Cloud\nUse functions from the R tm package to format the text so that you can create a word cloud:\n\n- Remove punctuation, numbers, and spaces\n- Remove very short words and very long words\n- Calculate the frequency of each word\n- Drop words that appear 8 or fewer times", 
            "metadata": {}, 
            "cell_type": "markdown"
        }, 
        {
            "execution_count": 10, 
            "source": "## Create Corpus from concatenated text\ncustomerCorpus <- Corpus(VectorSource(customerDocument))\n\n## Scrub text\ncustomerCorpus <- tm_map(customerCorpus, removePunctuation)\ncustomerCorpus <- tm_map(customerCorpus, removeNumbers)\ncustomerCorpus <- tm_map(customerCorpus, stripWhitespace)\n\n## Remove words less than 4 characters or greater than 20\ncustomerTDM <- TermDocumentMatrix(customerCorpus, control = list(wordLengths = c(4, 20)))\n\n## Calculate word frequencies\nwordFreqDF <- data.frame(word = row.names(as.matrix(customerTDM)), freq = as.vector(customerTDM))\n\n## Drop words with a count less than 8\nwordFreqDF <- subset(wordFreqDF, freq >= 8)", 
            "metadata": {
                "collapsed": true
            }, 
            "outputs": [], 
            "cell_type": "code"
        }, 
        {
            "source": "Look at the resulting wordFreDF DataFrame:", 
            "metadata": {}, 
            "cell_type": "markdown"
        }, 
        {
            "execution_count": 11, 
            "source": "wordFreqDF", 
            "metadata": {}, 
            "outputs": [
                {
                    "metadata": {}, 
                    "output_type": "display_data", 
                    "data": {
                        "text/latex": "\\begin{tabular}{r|ll}\n  & word & freq\\\\\n\\hline\n\t6 & access      &  9         \\\\\n\t56 & airlines    & 21         \\\\\n\t57 & airport     &  8         \\\\\n\t67 & amazon      & 22         \\\\\n\t69 & america     & 16         \\\\\n\t71 & american    & 23         \\\\\n\t80 & annual      &  8         \\\\\n\t82 & annuity     &  9         \\\\\n\t90 & apple       & 19         \\\\\n\t92 & appliance   & 13         \\\\\n\t115 & artificial  & 11         \\\\\n\t126 & association &  8         \\\\\n\t132 & attachments &  8         \\\\\n\t159 & bank        & 26         \\\\\n\t169 & battery     & 24         \\\\\n\t181 & best        & 23         \\\\\n\t214 & bond        &  9         \\\\\n\t221 & brands      & 15         \\\\\n\t234 & browser     & 10         \\\\\n\t237 & building    &  8         \\\\\n\t243 & business    & 49         \\\\\n\t269 & carbon      & 11         \\\\\n\t271 & card        & 16         \\\\\n\t274 & cards       & 19         \\\\\n\t275 & care        & 81         \\\\\n\t293 & center      &  9         \\\\\n\t307 & change      & 11         \\\\\n\t315 & chase       & 12         \\\\\n\t322 & chief       &  9         \\\\\n\t336 & city        & 15         \\\\\n\t... & ... & ...\\\\\n\t230 & states       & 33          \\\\\n\t231 & stock        & 17          \\\\\n\t232 & storage      & 13          \\\\\n\t233 & store        & 25          \\\\\n\t234 & supply       &  8          \\\\\n\t235 & system       & 13          \\\\\n\t236 & systems      & 28          \\\\\n\t237 & technologies & 14          \\\\\n\t238 & technology   & 30          \\\\\n\t239 & television   & 12          \\\\\n\t240 & term         & 16          \\\\\n\t241 & time         & 24          \\\\\n\t242 & trademark    & 10          \\\\\n\t243 & transport    & 23          \\\\\n\t244 & travel       &  8          \\\\\n\t245 & types        &  8          \\\\\n\t246 & underwriting & 18          \\\\\n\t247 & united       & 57          \\\\\n\t248 & universe     & 13          \\\\\n\t249 & vehicles     &  9          \\\\\n\t250 & verizon      & 11          \\\\\n\t251 & video        & 10          \\\\\n\t252 & walt         & 21          \\\\\n\t253 & want         &  8          \\\\\n\t254 & washington   & 15          \\\\\n\t255 & website      & 11          \\\\\n\t256 & wells        & 15          \\\\\n\t257 & wholesale    &  8          \\\\\n\t258 & world        & 59          \\\\\n\t259 & york         & 13          \\\\\n\\end{tabular}\n", 
                        "text/html": "<table>\n<thead><tr><th></th><th scope=col>word</th><th scope=col>freq</th></tr></thead>\n<tbody>\n\t<tr><th scope=row>6</th><td>access     </td><td> 9         </td></tr>\n\t<tr><th scope=row>56</th><td>airlines   </td><td>21         </td></tr>\n\t<tr><th scope=row>57</th><td>airport    </td><td> 8         </td></tr>\n\t<tr><th scope=row>67</th><td>amazon     </td><td>22         </td></tr>\n\t<tr><th scope=row>69</th><td>america    </td><td>16         </td></tr>\n\t<tr><th scope=row>71</th><td>american   </td><td>23         </td></tr>\n\t<tr><th scope=row>80</th><td>annual     </td><td> 8         </td></tr>\n\t<tr><th scope=row>82</th><td>annuity    </td><td> 9         </td></tr>\n\t<tr><th scope=row>90</th><td>apple      </td><td>19         </td></tr>\n\t<tr><th scope=row>92</th><td>appliance  </td><td>13         </td></tr>\n\t<tr><th scope=row>115</th><td>artificial </td><td>11         </td></tr>\n\t<tr><th scope=row>126</th><td>association</td><td> 8         </td></tr>\n\t<tr><th scope=row>132</th><td>attachments</td><td> 8         </td></tr>\n\t<tr><th scope=row>159</th><td>bank       </td><td>26         </td></tr>\n\t<tr><th scope=row>169</th><td>battery    </td><td>24         </td></tr>\n\t<tr><th scope=row>181</th><td>best       </td><td>23         </td></tr>\n\t<tr><th scope=row>214</th><td>bond       </td><td> 9         </td></tr>\n\t<tr><th scope=row>221</th><td>brands     </td><td>15         </td></tr>\n\t<tr><th scope=row>234</th><td>browser    </td><td>10         </td></tr>\n\t<tr><th scope=row>237</th><td>building   </td><td> 8         </td></tr>\n\t<tr><th scope=row>243</th><td>business   </td><td>49         </td></tr>\n\t<tr><th scope=row>269</th><td>carbon     </td><td>11         </td></tr>\n\t<tr><th scope=row>271</th><td>card       </td><td>16         </td></tr>\n\t<tr><th scope=row>274</th><td>cards      </td><td>19         </td></tr>\n\t<tr><th scope=row>275</th><td>care       </td><td>81         </td></tr>\n\t<tr><th scope=row>293</th><td>center     </td><td> 9         </td></tr>\n\t<tr><th scope=row>307</th><td>change     </td><td>11         </td></tr>\n\t<tr><th scope=row>315</th><td>chase      </td><td>12         </td></tr>\n\t<tr><th scope=row>322</th><td>chief      </td><td> 9         </td></tr>\n\t<tr><th scope=row>336</th><td>city       </td><td>15         </td></tr>\n\t<tr><th scope=row>...</th><td>...</td><td>...</td></tr>\n\t<tr><th scope=row>230</th><td>states      </td><td>33          </td></tr>\n\t<tr><th scope=row>231</th><td>stock       </td><td>17          </td></tr>\n\t<tr><th scope=row>232</th><td>storage     </td><td>13          </td></tr>\n\t<tr><th scope=row>233</th><td>store       </td><td>25          </td></tr>\n\t<tr><th scope=row>234</th><td>supply      </td><td> 8          </td></tr>\n\t<tr><th scope=row>235</th><td>system      </td><td>13          </td></tr>\n\t<tr><th scope=row>236</th><td>systems     </td><td>28          </td></tr>\n\t<tr><th scope=row>237</th><td>technologies</td><td>14          </td></tr>\n\t<tr><th scope=row>238</th><td>technology  </td><td>30          </td></tr>\n\t<tr><th scope=row>239</th><td>television  </td><td>12          </td></tr>\n\t<tr><th scope=row>240</th><td>term        </td><td>16          </td></tr>\n\t<tr><th scope=row>241</th><td>time        </td><td>24          </td></tr>\n\t<tr><th scope=row>242</th><td>trademark   </td><td>10          </td></tr>\n\t<tr><th scope=row>243</th><td>transport   </td><td>23          </td></tr>\n\t<tr><th scope=row>244</th><td>travel      </td><td> 8          </td></tr>\n\t<tr><th scope=row>245</th><td>types       </td><td> 8          </td></tr>\n\t<tr><th scope=row>246</th><td>underwriting</td><td>18          </td></tr>\n\t<tr><th scope=row>247</th><td>united      </td><td>57          </td></tr>\n\t<tr><th scope=row>248</th><td>universe    </td><td>13          </td></tr>\n\t<tr><th scope=row>249</th><td>vehicles    </td><td> 9          </td></tr>\n\t<tr><th scope=row>250</th><td>verizon     </td><td>11          </td></tr>\n\t<tr><th scope=row>251</th><td>video       </td><td>10          </td></tr>\n\t<tr><th scope=row>252</th><td>walt        </td><td>21          </td></tr>\n\t<tr><th scope=row>253</th><td>want        </td><td> 8          </td></tr>\n\t<tr><th scope=row>254</th><td>washington  </td><td>15          </td></tr>\n\t<tr><th scope=row>255</th><td>website     </td><td>11          </td></tr>\n\t<tr><th scope=row>256</th><td>wells       </td><td>15          </td></tr>\n\t<tr><th scope=row>257</th><td>wholesale   </td><td> 8          </td></tr>\n\t<tr><th scope=row>258</th><td>world       </td><td>59          </td></tr>\n\t<tr><th scope=row>259</th><td>york        </td><td>13          </td></tr>\n</tbody>\n</table>\n", 
                        "text/plain": "    word         freq\n6   access        9  \n56  airlines     21  \n57  airport       8  \n67  amazon       22  \n69  america      16  \n71  american     23  \n80  annual        8  \n82  annuity       9  \n90  apple        19  \n92  appliance    13  \n115 artificial   11  \n126 association   8  \n132 attachments   8  \n159 bank         26  \n169 battery      24  \n181 best         23  \n214 bond          9  \n221 brands       15  \n234 browser      10  \n237 building      8  \n243 business     49  \n269 carbon       11  \n271 card         16  \n274 cards        19  \n275 care         81  \n293 center        9  \n307 change       11  \n315 chase        12  \n322 chief         9  \n336 city         15  \n... ...          ... \n230 states       33  \n231 stock        17  \n232 storage      13  \n233 store        25  \n234 supply        8  \n235 system       13  \n236 systems      28  \n237 technologies 14  \n238 technology   30  \n239 television   12  \n240 term         16  \n241 time         24  \n242 trademark    10  \n243 transport    23  \n244 travel        8  \n245 types         8  \n246 underwriting 18  \n247 united       57  \n248 universe     13  \n249 vehicles      9  \n250 verizon      11  \n251 video        10  \n252 walt         21  \n253 want          8  \n254 washington   15  \n255 website      11  \n256 wells        15  \n257 wholesale     8  \n258 world        59  \n259 york         13  "
                    }
                }
            ], 
            "cell_type": "code"
        }, 
        {
            "source": "<a id='visualize6'></a>\n### 3.6 Visualize with the Brunel library\nFinally, use the Brunel library to visualize the word cloud to see themes amoung Fortune 100 companies.", 
            "metadata": {}, 
            "cell_type": "markdown"
        }, 
        {
            "execution_count": 12, 
            "source": "brunel (\" data('wordFreqDF') cloud color(word) size(freq) label(word) mean(freq) legends(none)\",\n        width = 800, height = 600, online_js = TRUE)", 
            "metadata": {}, 
            "outputs": [
                {
                    "metadata": {}, 
                    "output_type": "display_data", 
                    "data": {
                        "text/html": "<!--   ~ Copyright (c) 2015 IBM Corporation and others.   ~   ~ Licensed under the Apache License, Version 2.0 (the \"License\");   ~ You may not use this file except in compliance with the License.   ~ You may obtain a copy of the License at   ~   ~     http://www.apache.org/licenses/LICENSE-2.0   ~   ~ Unless required by applicable law or agreed to in writing, software   ~ distributed under the License is distributed on an \"AS IS\" BASIS,   ~ WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.   ~ See the License for the specific language governing permissions and   ~ limitations under the License.   -->  <link rel=\"stylesheet\" type=\"text/css\" href=\"https://brunelvis.org/js/brunel.2.3.css\"> <link rel=\"stylesheet\" type=\"text/css\" href=\"https://brunelvis.org/js/sumoselect.css\"> <style>      </style>  <div id=\"controlsb1f3001b-7f74-4085-956b-17a8c761ceaf\" class=\"brunel\"/> <svg id=\"vis3b86dc71-901d-4035-b469-d05d69baa129\" width=\"800\" height=\"600\"></svg>  <script>     require.config({         waitSeconds: 60,         paths: {             'd3': '//cdnjs.cloudflare.com/ajax/libs/d3/4.2.1/d3.min',             'topojson': '//cdnjs.cloudflare.com/ajax/libs/topojson/1.6.20/topojson.min',             'brunel' : 'https://brunelvis.org/js/brunel.2.3.min',             'brunelControls' : 'https://brunelvis.org/js/brunel.controls.2.3.min'         },         shim: {             'brunel' : {                  exports: 'BrunelD3',                  deps: ['d3', 'topojson'],                  init: function() {                     return {                       BrunelD3 : BrunelD3,                       BrunelData : BrunelData                    }                  }              },             'brunelControls' : {                  exports: 'BrunelEventHandlers',                  init: function() {                     return {                       BrunelEventHandlers: BrunelEventHandlers,                       BrunelJQueryControlFactory: BrunelJQueryControlFactory                    }                  }              }           }      });      require([\"d3\"], function(d3) {         require([\"brunel\", \"brunelControls\"], function(brunel, brunelControls) {             function  BrunelVis(visId) {\n  \"use strict\";                                                                       // strict mode\n  var datasets = [],                                      // array of datasets for the original data\n      pre = function(d, i) { return d },                         // default pre-process does nothing\n      post = function(d, i) { return d },                       // default post-process does nothing\n      transitionTime = 200,                                        // transition time for animations\n      charts = [],                                                       // the charts in the system\n      vis = d3.select('#' + visId).attr('class', 'brunel');                     // the SVG container\n\n  BrunelD3.addDefinitions(vis);                                   // ensure standard symbols present\n\n  // Define chart #1 in the visualization //////////////////////////////////////////////////////////\n\n  charts[0] = function(parentNode, filterRows) {\n    var geom = BrunelD3.geometry(parentNode || vis.node(), 0, 0, 1, 1, 0, 0, 0, 0),\n      elements = [];                                              // array of elements in this chart\n\n    // Define groups for the chart parts ///////////////////////////////////////////////////////////\n\n    var chart =  vis.append('g').attr('class', 'chart1')\n      .attr('transform','translate(' + geom.chart_left + ',' + geom.chart_top + ')');\n    var overlay = chart.append('g').attr('class', 'element').attr('class', 'overlay');\n    var zoom = d3.zoom().scaleExtent([1/3,3]);\n    var zoomNode = overlay.append('rect').attr('class', 'overlay')\n      .attr('x', geom.inner_left).attr('y', geom.inner_top)\n      .attr('width', geom.inner_rawWidth).attr('height', geom.inner_rawHeight)\n      .style('cursor', 'default')\n      .node();\n    zoomNode.__zoom = d3.zoomIdentity;\n    chart.append('rect').attr('class', 'background').attr('width', geom.chart_right-geom.chart_left).attr('height', geom.chart_bottom-geom.chart_top);\n    var interior = chart.append('g').attr('class', 'interior zoomNone')\n      .attr('transform','translate(' + geom.inner_left + ',' + geom.inner_top + ')')\n      .attr('clip-path', 'url(#clip_vis3b86dc71-901d-4035-b469-d05d69baa129_chart1_inner)');\n    interior.append('rect').attr('class', 'inner').attr('width', geom.inner_width).attr('height', geom.inner_height);\n    var gridGroup = interior.append('g').attr('class', 'grid');\n    vis.append('clipPath').attr('id', 'clip_vis3b86dc71-901d-4035-b469-d05d69baa129_chart1_inner').append('rect')\n      .attr('x', 0).attr('y', 0)\n      .attr('width', geom.inner_rawWidth+1).attr('height', geom.inner_rawHeight+1);\n    var scale_x = d3.scaleLinear(), scale_y = d3.scaleLinear();\n    var base_scales = [scale_x, scale_y];                           // untransformed original scales\n    zoom.on('zoom', function(t, time) {\n        t = t || d3.event.transform;\n        zoomNode.__zoom = t;\n        interior.attr('class', 'interior ' + BrunelD3.zoomLabel(t.k));;\n        interior.attr('transform', d3.zoomTransform(zoomNode));\n    });\n\n    // Define element #1 ///////////////////////////////////////////////////////////////////////////\n\n    elements[0] = function() {\n      var original, processed,                           // data sets passed in and then transformed\n        element, data,                                 // brunel element information and brunel data\n        selection, merged;                                      // d3 selection and merged selection\n      var elementGroup = interior.append('g').attr('class', 'element1')\n        .attr('transform','translate(' + geom.inner_width/2 + ',' + geom.inner_height/2 + ')'),\n        main = elementGroup.append('g').attr('class', 'main'),\n        labels = BrunelD3.undoTransform(elementGroup.append('g').attr('class', 'labels').attr('aria-hidden', 'true'), elementGroup);\n\n      function makeData() {\n        original = datasets[0];\n        if (filterRows) original = original.retainRows(filterRows);\n        processed = pre(original, 0)\n          .summarize('freq=freq:mean; word=word');\n        processed = post(processed, 0);\n        var f0 = processed.field('word'),\n          f1 = processed.field('freq'),\n          f2 = processed.field('#row'),\n          f3 = processed.field('#selection');\n        var keyFunc = function(d) { return f0.value(d) };\n        data = {\n          word:         function(d) { return f0.value(d.row) },\n          freq:         function(d) { return f1.value(d.row) },\n          $row:         function(d) { return f2.value(d.row) },\n          $selection:   function(d) { return f3.value(d.row) },\n          word_f:       function(d) { return f0.valueFormatted(d.row) },\n          freq_f:       function(d) { return f1.valueFormatted(d.row) },\n          $row_f:       function(d) { return f2.valueFormatted(d.row) },\n          $selection_f: function(d) { return f3.valueFormatted(d.row) },\n          _split:       function(d) { return f0.value(d.row)+ '|' + f1.value(d.row) },\n          _key:         keyFunc,\n          _rows:        BrunelD3.makeRowsWithKeys(keyFunc, processed.rowCount())\n        };\n      }\n      // Aesthetic Functions\n      var scale_color = d3.scaleOrdinal()\n        .domain(['access', 'airlines', 'airport', 'amazon', 'america', 'american', 'annual', 'annuity', 'apple', 'appliance', 'artificial', 'association', 'attachments', 'bank', 'battery', 'best', 'bond', 'brands', 'browser', 'building', 'business', 'carbon', 'card', 'cards', 'care', 'center', 'change', 'chase', 'chief', 'city', 'click', 'clinical', 'cloud', 'club', 'cocacola', 'commission', 'community', 'companies', 'company', 'computer', 'computing', 'conglomerate', 'contact', 'content', 'contract', 'controls', 'convenience', 'cookie', 'copyright', 'corporate', 'corporation', 'costco', 'countries', 'coverage', 'creativity', 'credit', 'current', 'customer', 'customers', 'data', 'deals', 'deception', 'delivery', 'delta', 'detroit', 'development', 'digital', 'dioxide', 'direct', 'disability', 'disease', 'disney', 'disneyland', 'drug', 'earth', 'economic', 'economics', 'email', 'energy', 'engine', 'englishlanguage', 'environment', 'equipment', 'exchange', 'executive', 'experience', 'express', 'family', 'fargo', 'farm', 'federal', 'film', 'films', 'finance', 'financial', 'food', 'foodservice', 'ford', 'form', 'francisco', 'future', 'futures', 'general', 'global', 'goldman', 'governance', 'group', 'growth', 'health', 'healthcare', 'hedge', 'help', 'history', 'home', 'hospital', 'hotels', 'housing', 'human', 'humana', 'index', 'industry', 'information', 'innovation', 'innovative', 'insurance', 'interest', 'international', 'internet', 'inventory', 'investment', 'iphone', 'ipod', 'islands', 'johnson', 'knowledge', 'language', 'largest', 'lawn', 'life', 'liquefied', 'local', 'long', 'lynch', 'management', 'market', 'marketing', 'media', 'medicine', 'menu', 'merrill', 'michigan', 'mobile', 'morgan', 'mortgage', 'motor', 'motors', 'mower', 'mutual', 'national', 'nationwide', 'natural', 'network', 'neural', 'news', 'number', 'office', 'officer', 'online', 'open', 'oracle', 'page', 'parks', 'partnership', 'patient', 'pension', 'personal', 'petroleum', 'pharmaceutical', 'pharmacology', 'pharmacy', 'phillips', 'phone', 'plan', 'plans', 'policy', 'power', 'prescription', 'press', 'pricing', 'printer', 'printing', 'privacy', 'problem', 'product', 'products', 'program', 'protection', 'provider', 'public', 'quality', 'quote', 'rally', 'rate', 'research', 'reserved', 'resort', 'resorts', 'retail', 'retirement', 'rights', 'risk', 'sachs', 'sales', 'saving', 'science', 'search', 'securities', 'service', 'services', 'share', 'shop', 'site', 'small', 'solutions', 'solving', 'spanish', 'stanley', 'starwood', 'state', 'states', 'stock', 'storage', 'store', 'supply', 'system', 'systems', 'technologies', 'technology', 'television', 'term', 'time', 'trademark', 'transport', 'travel', 'types', 'underwriting', 'united', 'universe', 'vehicles', 'verizon', 'video', 'walt', 'want', 'washington', 'website', 'wells', 'wholesale', 'world', 'york'])\n        .range([ '#00538A', '#C10020', '#F4C800', '#007D34', '#803E75', '#FF6800', \n          '#817066', '#FFB300', '#F6768E', '#93AA00', '#53377A', '#FF8E00', '#B32851', \n          '#CEA262', '#FF7A5C', '#7F180D', '#593315', '#F13A13', '#232C16']);\n      var color = function(d) { return scale_color(data.word(d)) };\n      var scale_size = d3.scaleSqrt().domain([0, 138.00001])\n        .range([ 0.001, 1]);\n      var size = function(d) { return scale_size(data.freq(d)) };\n\n      // Build element from data ///////////////////////////////////////////////////////////////////\n\n      function build(transitionMillis) {\n        element = elements[0];\n        // Build the cloud layout\n        var cloud = BrunelD3.cloudLayout(processed, [geom.inner_width, geom.inner_height], zoomNode);\n        function keyFunction(d) { return d.key };\n        main.attr('class', 'diagram cloud');\n\n        // Define selection entry operations\n        function initialState(selection) {\n          selection\n            .attr('class', 'element text filled')\n            .style('text-anchor', 'middle').classed('label', true)\n            .text(function(d) { return data.word_f(d) })\n            .style('font-size', function(d) { return (100*size(d)) + '%' })\n            .style('pointer-events', 'none')\n        }\n\n        // Define selection update operations on merged data\n        function updateState(selection) {\n          selection\n            .each(cloud.prepare).call(cloud.build)\n            .filter(BrunelD3.hasData)                     // following only performed for data items\n            .style('fill', color);\n        }\n        // Create selections, set the initial state and transition updates\n        selection = main.selectAll('.element').data(data._rows, function(d) { return d.key });\n        var added = selection.enter().append('text');\n        merged = selection.merge(added);\n        initialState(added);\n        selection.filter(BrunelD3.hasData)\n          .classed('selected', BrunelD3.isSelected(data))\n          .filter(BrunelD3.isSelected(data)).raise();\n        updateState(BrunelD3.transition(merged, transitionMillis));\n\n        BrunelD3.transition(selection.exit(), transitionMillis/3)\n          .style('opacity', 0.5).each( function() {\n            this.remove(); BrunelD3.removeLabels(this); \n        });\n      }\n\n      return {\n        data:           function() { return processed },\n        original:       function() { return original },\n        internal:       function() { return data },\n        selection:      function() { return merged },\n        makeData:       makeData,\n        build:          build,\n        chart:          function() { return charts[0] },\n        group:          function() { return elementGroup },\n        fields: {\n          key:          ['word'],\n          color:        ['word'],\n          size:         ['freq']\n        }\n      };\n    }();\n\n    function build(time, noData) {\n      var first = elements[0].data() == null;\n      if (first) time = 0;                                           // no transition for first call\n      if ((first || time > -1) && !noData) {\n        elements[0].makeData();\n      }\n      elements[0].build(time);\n    }\n\n    // Expose the following components of the chart\n    return {\n      elements : elements,\n      interior : interior,\n      zoom: function(params, time) {\n          if (params) zoom.on('zoom').call(zoomNode, params, time);\n          return d3.zoomTransform(zoomNode);\n      },\n      build : build\n    };\n    }();\n\n  function setData(rowData, i) { datasets[i||0] = BrunelD3.makeData(rowData) }\n  function updateAll(time) { charts.forEach(function(x) {x.build(time || 0)}) }\n  function buildAll() {\n    for (var i=0;i<arguments.length;i++) setData(arguments[i], i);\n    updateAll(transitionTime);\n  }\n\n  return {\n    dataPreProcess:     function(f) { if (f) pre = f; return pre },\n    dataPostProcess:    function(f) { if (f) post = f; return post },\n    data:               function(d,i) { if (d) setData(d,i); return datasets[i||0] },\n    visId:              visId,\n    build:              buildAll,\n    rebuild:            updateAll,\n    charts:             charts\n  }\n}\n\n// Data Tables /////////////////////////////////////////////////////////////////////////////////////\n\nvar table1 = {\n   summarized: true,\n   names: ['word', 'freq'], \n   options: ['string', 'numeric'], \n   rows: [['access', 9], ['airlines', 21], ['airport', 8], ['amazon', 22], ['america', 16],\n  ['american', 23], ['annual', 8], ['annuity', 9], ['apple', 19], ['appliance', 13],\n  ['artificial', 11], ['association', 8], ['attachments', 8], ['bank', 26], ['battery', 24],\n  ['best', 23], ['bond', 9], ['brands', 15], ['browser', 10], ['building', 8], ['business', 49],\n  ['carbon', 11], ['card', 16], ['cards', 19], ['care', 81], ['center', 9], ['change', 11],\n  ['chase', 12], ['chief', 9], ['city', 15], ['click', 11], ['clinical', 8], ['cloud', 24],\n  ['club', 16], ['cocacola', 11], ['commission', 11], ['community', 9], ['companies', 20],\n  ['company', 56], ['computer', 15], ['computing', 20], ['conglomerate', 9], ['contact', 11],\n  ['content', 10], ['contract', 14], ['controls', 8], ['convenience', 9], ['cookie', 9],\n  ['copyright', 13], ['corporate', 26], ['corporation', 39], ['costco', 13], ['countries', 13],\n  ['coverage', 9], ['creativity', 12], ['credit', 29], ['current', 13], ['customer', 38],\n  ['customers', 9], ['data', 15], ['deals', 18], ['deception', 10], ['delivery', 9], ['delta', 8],\n  ['detroit', 10], ['development', 8], ['digital', 21], ['dioxide', 10], ['direct', 9],\n  ['disability', 11], ['disease', 9], ['disney', 36], ['disneyland', 11], ['drug', 17], ['earth', 9],\n  ['economic', 17], ['economics', 24], ['email', 9], ['energy', 47], ['engine', 10],\n  ['englishlanguage', 17], ['environment', 18], ['equipment', 8], ['exchange', 16],\n  ['executive', 11], ['experience', 24], ['express', 23], ['family', 8], ['fargo', 16], ['farm', 9],\n  ['federal', 8], ['film', 11], ['films', 21], ['finance', 40], ['financial', 66], ['food', 18],\n  ['foodservice', 8], ['ford', 18], ['form', 12], ['francisco', 10], ['future', 18], ['futures', 16],\n  ['general', 21], ['global', 36], ['goldman', 15], ['governance', 14], ['group', 10],\n  ['growth', 14], ['health', 137], ['healthcare', 8], ['hedge', 10], ['help', 8], ['history', 8],\n  ['home', 37], ['hospital', 13], ['hotels', 9], ['housing', 8], ['human', 12], ['humana', 18],\n  ['index', 10], ['industry', 9], ['information', 33], ['innovation', 24], ['innovative', 8],\n  ['insurance', 138], ['interest', 10], ['international', 14], ['internet', 20], ['inventory', 12],\n  ['investment', 51], ['iphone', 11], ['ipod', 12], ['islands', 17], ['johnson', 8],\n  ['knowledge', 14], ['language', 14], ['largest', 10], ['lawn', 10], ['life', 32],\n  ['liquefied', 15], ['local', 20], ['long', 8], ['lynch', 8], ['management', 61], ['market', 21],\n  ['marketing', 21], ['media', 9], ['medicine', 38], ['menu', 10], ['merrill', 12], ['michigan', 10],\n  ['mobile', 29], ['morgan', 16], ['mortgage', 14], ['motor', 10], ['motors', 11], ['mower', 9],\n  ['mutual', 32], ['national', 11], ['nationwide', 14], ['natural', 35], ['network', 17],\n  ['neural', 12], ['news', 8], ['number', 8], ['office', 10], ['officer', 9], ['online', 11],\n  ['open', 8], ['oracle', 10], ['page', 8], ['parks', 8], ['partnership', 9], ['patient', 10],\n  ['pension', 10], ['personal', 30], ['petroleum', 29], ['pharmaceutical', 15], ['pharmacology', 15],\n  ['pharmacy', 24], ['phillips', 11], ['phone', 14], ['plan', 15], ['plans', 12], ['policy', 37],\n  ['power', 8], ['prescription', 9], ['press', 8], ['pricing', 9], ['printer', 10], ['printing', 8],\n  ['privacy', 35], ['problem', 10], ['product', 8], ['products', 43], ['program', 10],\n  ['protection', 10], ['provider', 17], ['public', 21], ['quality', 8], ['quote', 9], ['rally', 10],\n  ['rate', 8], ['research', 16], ['reserved', 13], ['resort', 11], ['resorts', 15], ['retail', 8],\n  ['retirement', 8], ['rights', 41], ['risk', 33], ['sachs', 10], ['sales', 25], ['saving', 8],\n  ['science', 10], ['search', 13], ['securities', 17], ['service', 28], ['services', 80],\n  ['share', 12], ['shop', 15], ['site', 14], ['small', 11], ['solutions', 13], ['solving', 10],\n  ['spanish', 9], ['stanley', 10], ['starwood', 9], ['state', 10], ['states', 33], ['stock', 17],\n  ['storage', 13], ['store', 25], ['supply', 8], ['system', 13], ['systems', 28],\n  ['technologies', 14], ['technology', 30], ['television', 12], ['term', 16], ['time', 24],\n  ['trademark', 10], ['transport', 23], ['travel', 8], ['types', 8], ['underwriting', 18],\n  ['united', 57], ['universe', 13], ['vehicles', 9], ['verizon', 11], ['video', 10], ['walt', 21],\n  ['want', 8], ['washington', 15], ['website', 11], ['wells', 15], ['wholesale', 8], ['world', 59],\n  ['york', 13]]\n};\n\n// Call Code to Build the system ///////////////////////////////////////////////////////////////////\n\nvar v  = new BrunelVis('vis3b86dc71-901d-4035-b469-d05d69baa129');\nv.build(table1);\n         });     });  </script>"
                    }
                }
            ], 
            "cell_type": "code"
        }, 
        {
            "source": "<a id='summary'></a>\n## Summary and next steps\n\nCongratulations! In this notebook you learned about the Watson Natural Language Understanding API and how to access it in a programmatic way by using the R programming language.  \n\nTry substituting your own client list for the Fortune 100 data and creating a word cloud.\n\n### Author\n\n**Rafi Kurlansik** is an Open Source Solutions Engineer specializing in big data technologies, such as Hadoop and Spark. He's responsible for developing and delivering demonstrations of IBM tech to both enterprise clients and the larger analytics community. Kurlansik has hands-on experience with machine learning, natural language processing, data visualization, and dashboard development. If you're wondering where he comes down on the biggest data science debate of our day, Rafi is, in his own words, \"an avid R fan, especially RStudio!\" ", 
            "metadata": {}, 
            "cell_type": "markdown"
        }, 
        {
            "source": "Copyright \u00a9 2017 IBM. This notebook and its source code are released under the terms of the MIT License.", 
            "metadata": {}, 
            "cell_type": "markdown"
        }
    ]
}